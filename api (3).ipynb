{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab6f3cf5-9484-4ffb-a562-8c9def2e953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json, os, time\n",
    "import requests\n",
    "import random\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_START = datetime(2026, 1, 30)\n",
    "DATA_END = datetime(2026, 2, 5)\n",
    "DUMMY_PATH = 'dummy.json'\n",
    "REAL_URL = \"https://dummyjson.com/products\"\n",
    "KEY_FILE = 'key.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d177d97-0cc9-4b3e-8689-0e015ceeb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_window(start, end, window_days: int = 2):\n",
    "    \"\"\"\n",
    "    Generate a random time window between of fixed length (window_days) between 'start' and 'end'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start : The start of the overall time range.\n",
    "    end : The end of the overall time range.\n",
    "    window_days : The window of time the start and end range is.\n",
    "\n",
    "    \"\"\"\n",
    "    total_seconds = int((end - start).total_seconds())\n",
    "    window_seconds = window_days * 86400 # convert days to seconds\n",
    "    \n",
    "    if total_seconds < window_seconds:\n",
    "        raise ValueError(f\"Time range must be at least {windows_days} days long.\")\n",
    "\n",
    "    # pick random start point\n",
    "    rand_start_seconds = random.randint(0, total_seconds - window_seconds)\n",
    "    rand_start = start + timedelta(seconds=rand_start_seconds)\n",
    "    rand_end = rand_start + timedelta(days=window_days)\n",
    "\n",
    "    return (\n",
    "        rand_start.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        rand_end.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    )\n",
    "\n",
    "def random_comment_window(tweet_created_at, window_days: int = 2):\n",
    "    \"\"\"\n",
    "    Create a random comment window starting after the tweet timestamp.\n",
    "    \"\"\"\n",
    "    tweet_time = datetime.fromisoformat(tweet_created_at.replace(\"Z\", \"+00:00\"))\n",
    "    now = datetime.now(timezone.utc) - timedelta(seconds=15) # offsetting the time for acceptable api timing\n",
    "\n",
    "    # max time you’re allowed to search comments\n",
    "    max_end = min(tweet_time + timedelta(days=window_days), now)\n",
    "\n",
    "    if max_end <= tweet_time:\n",
    "        raise ValueError(\"Tweet is in the future or no valid comment window.\")\n",
    "\n",
    "    # pick a random start\n",
    "    delta_seconds = int((max_end - tweet_time).total_seconds() - window_days * 86400)\n",
    "    delta_seconds = max(delta_seconds, 0)\n",
    "    \n",
    "    rand_start_seconds = random.randint(0, delta_seconds) if delta_seconds > 0 else 0\n",
    "    rand_start = tweet_time + timedelta(seconds=rand_start_seconds)\n",
    "\n",
    "    rand_end = min(rand_start + timedelta(days = window_days), max_end)\n",
    "\n",
    "    return (\n",
    "        rand_start.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        rand_end.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    )\n",
    "    \n",
    "def save_json(data: dict, folder: str, filename: str):\n",
    "    \"\"\"\n",
    "    Function to save dictionaries as jsons\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    path = os.path.join(folder, filename)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved → {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b5550bf-0df7-4cbf-a2c3-622a534fc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfinished Dummy API code\n",
    "\n",
    "class BaseAPIClient(ABC):\n",
    "    '''\n",
    "    We only use this class to define a structure\n",
    "    and then inherit it. Never use this class directly.\n",
    "    '''\n",
    "\n",
    "    @abstractmethod # allows you to define a function with no purpose\n",
    "    def fetch_data(self) -> dict:\n",
    "        pass # doesnt do anything\n",
    "        \n",
    "class DummyAPIClient(BaseAPIClient):\n",
    "    '''\n",
    "    Since this inherist the BaseAPIClient it must\n",
    "    implement all of its abstract methods\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        print('running in dummy mode')\n",
    "        return\n",
    "\n",
    "    def fetch_data(self) -> dict:\n",
    "        '''\n",
    "        Load and return the local dummy data\n",
    "        '''\n",
    "        with open(DUMMY_PATH, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "# START of script\n",
    "\n",
    "class RealAPIClient(BaseAPIClient):\n",
    "    '''\n",
    "    Since this inherist the BaseAPIClient it must\n",
    "    implement all of its abstract methods\n",
    "    '''\n",
    "    def __init__(self, key, bearer):\n",
    "        self.key = key\n",
    "        self.bearer = bearer\n",
    "        return\n",
    "        \n",
    "    def fetch_data(self) -> dict:\n",
    "        \"\"\"Placeholder to satisfy abstract method requirement.\"\"\"\n",
    "        return {}\n",
    "\n",
    "    def fetch_posts(self,\n",
    "                    politician_handle: str,\n",
    "                    randomize_time=True,\n",
    "                    target_count=10\n",
    "                   ):\n",
    "        politician_folder = f\"data/posts/{politician_handle}\"\n",
    "        os.makedirs(politician_folder, exist_ok=True)\n",
    "\n",
    "        posts_path = f\"{politician_folder}/{politician_handle}_posts.json\"\n",
    "\n",
    "        existing_posts = []\n",
    "        collected_post_ids = set()\n",
    "\n",
    "        # Load posts into exisitng_posts if they exist\n",
    "        if os.path.exists(posts_path):\n",
    "            with open(posts_path, \"r\") as f:\n",
    "                existing_posts = json.load(f).get(\"data\", [])\n",
    "                collected_post_ids = {tweet[\"id\"] for tweet in existing_posts}\n",
    "\n",
    "        # if we have enough posts, STOP\n",
    "        if len(existing_posts) >= target_count:\n",
    "            print(f\"Already have {len(existing_posts)} posts for {politician_handle}\")\n",
    "            return {\"data\": existing_posts[:target_count]}, [p[\"id\"] for p in existing_posts[:target_count]]\n",
    "\n",
    "        collected_posts = existing_posts[:]\n",
    "\n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.bearer}\"}\n",
    "        \n",
    "        attempts = 0\n",
    "        while len(collected_posts) < target_count and attempts <5: # ensures that we only collect 10 posts in each folder\n",
    "            attempts += 1\n",
    "            added_this_round = 0 # number of posts added to the folder\n",
    "            # Step 1: Set or randomize timeframe\n",
    "            if randomize_time:\n",
    "                start, end = random_time_window(DATA_START, DATA_END)\n",
    "            else:\n",
    "                # manually set date window here\n",
    "                start = \"2025-12-16T19:00:00Z\"\n",
    "                end   = \"2025-12-16T21:00:00Z\"\n",
    "\n",
    "            print(f\"Fetching tweets for {politician_handle} between {start} and {end}\")\n",
    "\n",
    "            params = {\n",
    "                \"query\": f\"from:{politician_handle} -is:retweet\", # no retweets!\n",
    "                \"start_time\": start,\n",
    "                \"end_time\": end,\n",
    "                \"max_results\": 10,\n",
    "                \"tweet.fields\": \"id,text,created_at\"\n",
    "            }\n",
    "    \n",
    "            # Get response\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                print(\"SUCCESS\")\n",
    "                data = response.json().get(\"data\", [])\n",
    "                for tweet in data:\n",
    "                    pid = tweet[\"id\"]\n",
    "                    if pid not in collected_post_ids:\n",
    "                        #print(f\"Skipping post {pid} — already saved\")\n",
    "                        collected_posts.append(tweet)\n",
    "                        collected_post_ids.add(pid)\n",
    "                        added_this_round += 1\n",
    "                    # only collect 10 posts in the foslder\n",
    "                    if len(collected_posts) >= target_count:\n",
    "                        break\n",
    "                if added_this_round == 0:\n",
    "                    print(\"No new posts found - stopping early\")\n",
    "                    continue\n",
    "                        \n",
    "            elif response.status_code == 429:\n",
    "                reset = response.headers.get(\"x-rate-limit-reset\")\n",
    "                wait = int(reset) - int(time.time()) if reset else 60\n",
    "                print(f\"→ RATE LIMIT HIT. Sleeping {wait} seconds…\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(\"Error:\", response.text)\n",
    "                response.raise_for_status()\n",
    "\n",
    "        # SAVE FINAL POSTS\n",
    "        if collected_posts:\n",
    "            save_json(\n",
    "                {\"data\": collected_posts[:target_count]},\n",
    "                folder=politician_folder,\n",
    "                filename=f\"{politician_handle}_posts.json\"\n",
    "            )\n",
    "        return {\"data\": collected_posts[:target_count]}, [p[\"id\"] for p in collected_posts[:target_count]]\n",
    "\n",
    "    def fetch_comments(self,\n",
    "                       politician_handle: str,\n",
    "                       post_id: str,\n",
    "                       tweet_created_at: str,\n",
    "                       target_count=10,\n",
    "                       randomize_time: bool = True\n",
    "                      ):\n",
    "        post_folder = f\"data/posts/{politician_handle}/{post_id}\"\n",
    "        os.makedirs(post_folder, exist_ok=True)\n",
    "\n",
    "        comments_path = os.path.join(post_folder, \"comments.json\")\n",
    "        \n",
    "        existing_comments = []\n",
    "        existing_comment_ids = set()\n",
    "    \n",
    "        # LOAD EXISTING COMMENTS\n",
    "        if os.path.exists(comments_path):\n",
    "            with open(comments_path, \"r\") as f:\n",
    "                existing_comments = json.load(f).get(\"data\", [])\n",
    "                existing_comment_ids = {c[\"id\"] for c in existing_comments}\n",
    "        else:\n",
    "            existing_comments = []\n",
    "    \n",
    "        if len(existing_comments) >= target_count:\n",
    "            print(f\"Already have {len(existing_comments)} comments for {post_id}\")\n",
    "            return existing_comments[:target_count]\n",
    "    \n",
    "        collected_comments = existing_comments[:]\n",
    "\n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.bearer}\"}\n",
    "\n",
    "        attempts = 0\n",
    "        while len(collected_comments) < target_count and attempts < 10:\n",
    "            attempts += 1\n",
    "            added_this_round = 0\n",
    "            \n",
    "            # Define Timeframe\n",
    "            start, end = random_comment_window(tweet_created_at, window_days=2)\n",
    "            print(f\"Fetching comments for {post_id} between {start} and {end}\")\n",
    "            \n",
    "            params = {\"query\": f\"conversation_id:{post_id}\",\n",
    "                      \"start_time\": start,\n",
    "                      \"end_time\": end,\n",
    "                      \"max_results\": 10,\n",
    "                     \"tweet.fields\": \"id,text,created_at\"}\n",
    "    \n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(\"SUCCESS\")\n",
    "                data = response.json().get(\"data\", [])\n",
    "\n",
    "                for tweet in data:\n",
    "                    cid = tweet['id']\n",
    "                    if cid not in existing_comment_ids:\n",
    "                        collected_comments.append(tweet)\n",
    "                        existing_comment_ids.add(cid)\n",
    "                        added_this_round += 1\n",
    "\n",
    "                    if len(collected_comments) >= target_count:\n",
    "                        break\n",
    "                if added_this_round == 0:\n",
    "                    print(\"No new comments found - stopping early\")\n",
    "                    break\n",
    "                \n",
    "            elif response.status_code == 429:\n",
    "                reset = response.headers.get(\"x-rate-limit-reset\")\n",
    "                wait = int(reset) - int(time.time()) if reset else 60\n",
    "                print(f\"→ RATE LIMIT HIT. Sleeping {wait} seconds…\")\n",
    "                time.sleep(wait)\n",
    "            else: #other Errors\n",
    "                print(\"→ ERROR:\", response.text)\n",
    "                response.raise_for_status()\n",
    "\n",
    "        save_json({\"data\": collected_comments[:target_count]},\n",
    "                  folder=post_folder,\n",
    "                  filename=\"comments.json\")\n",
    "\n",
    "        return collected_comments[:target_count]\n",
    "\n",
    "class ToxicityApp:\n",
    "    def __init__(self):\n",
    "        if self.load_key():\n",
    "            self.api = RealAPIClient(self.key, self.bearer)\n",
    "        else:\n",
    "            self.api = DummyAPIClient()\n",
    "\n",
    "    def load_key(self):\n",
    "        try:\n",
    "            with open(\"key.json\") as f:\n",
    "                data = json.load(f)\n",
    "                self.key = data[\"X_API_KEY\"]\n",
    "                self.bearer = data[\"bearer_token\"]\n",
    "            return True\n",
    "        except:\n",
    "            print(\"Could not load key.\")\n",
    "            return False\n",
    "\n",
    "    def collect_politician_comments(self, \n",
    "                                    handles: list[str], \n",
    "                                    randomize_time: bool = True\n",
    "                                   ):\n",
    "        \"\"\"\n",
    "        Handes a list of twitter handles, returns json of posts and comments\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for handle in handles:\n",
    "            print(f\"Collecting posts for {handle}\")\n",
    "            \n",
    "            posts_json, post_ids = self.api.fetch_posts(handle)\n",
    "            tweets = posts_json.get(\"data\", [])\n",
    "\n",
    "            if not post_ids:\n",
    "                print(f\"No posts found for {handle}.\")\n",
    "                results[handle] = {\"posts\": posts_json, \"comments\": {}}\n",
    "                continue\n",
    "                \n",
    "            comments_for_this_handle = {}\n",
    "\n",
    "            # Iterate posts\n",
    "            for tweet in tweets:\n",
    "                post_id = tweet[\"id\"]\n",
    "                created_at = tweet[\"created_at\"]\n",
    "\n",
    "                comment_data = self.api.fetch_comments(\n",
    "                    politician_handle=handle,\n",
    "                    post_id=post_id,\n",
    "                    tweet_created_at = created_at,\n",
    "                    target_count=10,\n",
    "                    randomize_time=randomize_time)\n",
    "                comments_for_this_handle[post_id] = comment_data\n",
    "        \n",
    "            # Store inside the results dictionary\n",
    "            results[handle] = {\n",
    "                \"posts\" : posts_json,\n",
    "                \"comments\": comments_for_this_handle\n",
    "            }\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d408168-63f4-4063-86c5-745f015e3e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load key.\n",
      "running in dummy mode\n",
      "Collecting posts for SenTuberville\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DummyAPIClient' object has no attribute 'fetch_posts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m app = ToxicityApp()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_politician_comments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenTuberville\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenKatieBritt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlisamurkowski\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenDanSullivan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenRubenGallego\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenMarkKelly\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mJohnBoozman\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSenTomCotton\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAlexPadilla4CA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdamSchiff\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMichaelBennet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomize_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 246\u001b[39m, in \u001b[36mToxicityApp.collect_politician_comments\u001b[39m\u001b[34m(self, handles, randomize_time)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m handles:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollecting posts for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhandle\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     posts_json, post_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_posts\u001b[49m(handle)\n\u001b[32m    247\u001b[39m     tweets = posts_json.get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m post_ids:\n",
      "\u001b[31mAttributeError\u001b[39m: 'DummyAPIClient' object has no attribute 'fetch_posts'"
     ]
    }
   ],
   "source": [
    "app = ToxicityApp()\n",
    "\n",
    "results = app.collect_politician_comments(\n",
    "    [\"SenTuberville\",\n",
    "     \"SenKatieBritt\",\n",
    "     \"lisamurkowski\",\n",
    "     \"SenDanSullivan\",\n",
    "     \"SenRubenGallego\",\n",
    "     \"SenMarkKelly\",\n",
    "     \"JohnBoozman\",\n",
    "     \"SenTomCotton\",\n",
    "     \"AlexPadilla4CA\",\n",
    "     \"AdamSchiff\",\n",
    "     \"MichaelBennet\"\n",
    "    ],\n",
    "    randomize_time=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd75d9-c320-4ee6-9640-a758eb7fc632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cc0e0-f1c1-45b3-a5f6-886fec9c897e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
