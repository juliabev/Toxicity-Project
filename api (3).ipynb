{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6f3cf5-9484-4ffb-a562-8c9def2e953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json, os, time\n",
    "import requests\n",
    "import random\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_START = datetime(2026, 2, 4)\n",
    "DATA_END = datetime(2026, 2, 10)\n",
    "DUMMY_PATH = 'dummy.json'\n",
    "REAL_URL = \"https://dummyjson.com/products\"\n",
    "KEY_FILE = 'key.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d177d97-0cc9-4b3e-8689-0e015ceeb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_window(start, end, window_days: int = 2):\n",
    "    \"\"\"\n",
    "    Generate a random time window between of fixed length (window_days) between 'start' and 'end'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start : The start of the overall time range.\n",
    "    end : The end of the overall time range.\n",
    "    window_days : The window of time the start and end range is.\n",
    "\n",
    "    \"\"\"\n",
    "    total_seconds = int((end - start).total_seconds())\n",
    "    window_seconds = window_days * 86400 # convert days to seconds\n",
    "    \n",
    "    if total_seconds < window_seconds:\n",
    "        raise ValueError(f\"Time range must be at least {windows_days} days long.\")\n",
    "\n",
    "    # pick random start point\n",
    "    rand_start_seconds = random.randint(0, total_seconds - window_seconds)\n",
    "    rand_start = start + timedelta(seconds=rand_start_seconds)\n",
    "    rand_end = rand_start + timedelta(days=window_days)\n",
    "\n",
    "    return (\n",
    "        rand_start.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        rand_end.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    )\n",
    "\n",
    "def random_comment_window(tweet_created_at, window_days: int = 2):\n",
    "    \"\"\"\n",
    "    Create a random comment window starting after the tweet timestamp.\n",
    "    \"\"\"\n",
    "    tweet_time = datetime.fromisoformat(tweet_created_at.replace(\"Z\", \"+00:00\"))\n",
    "    now = datetime.now(timezone.utc) - timedelta(seconds=15) # offsetting the time for acceptable api timing\n",
    "\n",
    "    # max time you’re allowed to search comments\n",
    "    max_end = min(tweet_time + timedelta(days=window_days), now)\n",
    "\n",
    "    if max_end <= tweet_time:\n",
    "        raise ValueError(\"Tweet is in the future or no valid comment window.\")\n",
    "\n",
    "    # pick a random start\n",
    "    delta_seconds = int((max_end - tweet_time).total_seconds() - window_days * 86400)\n",
    "    delta_seconds = max(delta_seconds, 0)\n",
    "    \n",
    "    rand_start_seconds = random.randint(0, delta_seconds) if delta_seconds > 0 else 0\n",
    "    rand_start = tweet_time + timedelta(seconds=rand_start_seconds)\n",
    "\n",
    "    rand_end = min(rand_start + timedelta(days = window_days), max_end)\n",
    "\n",
    "    return (\n",
    "        rand_start.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        rand_end.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    )\n",
    "    \n",
    "def save_json(data: dict, folder: str, filename: str):\n",
    "    \"\"\"\n",
    "    Function to save dictionaries as jsons\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    path = os.path.join(folder, filename)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"Saved → {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5550bf-0df7-4cbf-a2c3-622a534fc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfinished Dummy API code\n",
    "\n",
    "class BaseAPIClient(ABC):\n",
    "    '''\n",
    "    We only use this class to define a structure\n",
    "    and then inherit it. Never use this class directly.\n",
    "    '''\n",
    "\n",
    "    @abstractmethod # allows you to define a function with no purpose\n",
    "    def fetch_data(self) -> dict:\n",
    "        pass # doesnt do anything\n",
    "        \n",
    "class DummyAPIClient(BaseAPIClient):\n",
    "    '''\n",
    "    Since this inherist the BaseAPIClient it must\n",
    "    implement all of its abstract methods\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        print('running in dummy mode')\n",
    "        return\n",
    "\n",
    "    def fetch_data(self) -> dict:\n",
    "        '''\n",
    "        Load and return the local dummy data\n",
    "        '''\n",
    "        with open(DUMMY_PATH, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "\n",
    "# START of script\n",
    "\n",
    "class RealAPIClient(BaseAPIClient):\n",
    "    '''\n",
    "    Since this inherist the BaseAPIClient it must\n",
    "    implement all of its abstract methods\n",
    "    '''\n",
    "    def __init__(self, key, bearer):\n",
    "        self.key = key\n",
    "        self.bearer = bearer\n",
    "        return\n",
    "        \n",
    "    def fetch_data(self) -> dict:\n",
    "        \"\"\"Placeholder to satisfy abstract method requirement.\"\"\"\n",
    "        return {}\n",
    "\n",
    "    def fetch_posts(self,\n",
    "                    politician_handle: str,\n",
    "                    randomize_time=True,\n",
    "                    target_count=10\n",
    "                   ):\n",
    "        politician_folder = f\"data/posts/{politician_handle}\"\n",
    "        os.makedirs(politician_folder, exist_ok=True)\n",
    "\n",
    "        posts_path = f\"{politician_folder}/{politician_handle}_posts.json\"\n",
    "\n",
    "        existing_posts = []\n",
    "        collected_post_ids = set()\n",
    "\n",
    "        # Load posts into exisitng_posts if they exist\n",
    "        if os.path.exists(posts_path):\n",
    "            with open(posts_path, \"r\") as f:\n",
    "                existing_posts = json.load(f).get(\"data\", [])\n",
    "                collected_post_ids = {tweet[\"id\"] for tweet in existing_posts}\n",
    "\n",
    "        # if we have enough posts, STOP\n",
    "        if len(existing_posts) >= target_count:\n",
    "            print(f\"Already have {len(existing_posts)} posts for {politician_handle}\")\n",
    "            return {\"data\": existing_posts[:target_count]}, [p[\"id\"] for p in existing_posts[:target_count]]\n",
    "\n",
    "        collected_posts = existing_posts[:]\n",
    "\n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.bearer}\"}\n",
    "        \n",
    "        attempts = 0\n",
    "        while len(collected_posts) < target_count and attempts <5: # ensures that we only collect 10 posts in each folder\n",
    "            attempts += 1\n",
    "            added_this_round = 0 # number of posts added to the folder\n",
    "            # Step 1: Set or randomize timeframe\n",
    "            if randomize_time:\n",
    "                start, end = random_time_window(DATA_START, DATA_END)\n",
    "            else:\n",
    "                # manually set date window here\n",
    "                start = \"2025-12-16T19:00:00Z\"\n",
    "                end   = \"2025-12-16T21:00:00Z\"\n",
    "\n",
    "            print(f\"Fetching tweets for {politician_handle} between {start} and {end}\")\n",
    "\n",
    "            params = {\n",
    "                \"query\": f\"from:{politician_handle} -is:retweet\", # no retweets!\n",
    "                \"start_time\": start,\n",
    "                \"end_time\": end,\n",
    "                \"max_results\": 10,\n",
    "                \"tweet.fields\": \"id,text,created_at\"\n",
    "            }\n",
    "    \n",
    "            # Get response\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                print(\"SUCCESS\")\n",
    "                data = response.json().get(\"data\", [])\n",
    "                for tweet in data:\n",
    "                    pid = tweet[\"id\"]\n",
    "                    if pid not in collected_post_ids:\n",
    "                        #print(f\"Skipping post {pid} — already saved\")\n",
    "                        collected_posts.append(tweet)\n",
    "                        collected_post_ids.add(pid)\n",
    "                        added_this_round += 1\n",
    "                    # only collect 10 posts in the foslder\n",
    "                    if len(collected_posts) >= target_count:\n",
    "                        break\n",
    "                if added_this_round == 0:\n",
    "                    print(\"No new posts found - stopping early\")\n",
    "                    continue\n",
    "                        \n",
    "            elif response.status_code == 429:\n",
    "                reset = response.headers.get(\"x-rate-limit-reset\")\n",
    "                wait = int(reset) - int(time.time()) if reset else 60\n",
    "                print(f\"→ RATE LIMIT HIT. Sleeping {wait} seconds…\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(\"Error:\", response.text)\n",
    "                response.raise_for_status()\n",
    "\n",
    "        # SAVE FINAL POSTS\n",
    "        if collected_posts:\n",
    "            save_json(\n",
    "                {\"data\": collected_posts[:target_count]},\n",
    "                folder=politician_folder,\n",
    "                filename=f\"{politician_handle}_posts.json\"\n",
    "            )\n",
    "        return {\"data\": collected_posts[:target_count]}, [p[\"id\"] for p in collected_posts[:target_count]]\n",
    "\n",
    "    def fetch_comments(self,\n",
    "                       politician_handle: str,\n",
    "                       post_id: str,\n",
    "                       tweet_created_at: str,\n",
    "                       target_count=10,\n",
    "                       randomize_time: bool = True\n",
    "                      ):\n",
    "        post_folder = f\"data/posts/{politician_handle}/{post_id}\"\n",
    "        os.makedirs(post_folder, exist_ok=True)\n",
    "\n",
    "        comments_path = os.path.join(post_folder, \"comments.json\")\n",
    "        \n",
    "        existing_comments = []\n",
    "        existing_comment_ids = set()\n",
    "    \n",
    "        # LOAD EXISTING COMMENTS\n",
    "        if os.path.exists(comments_path):\n",
    "            with open(comments_path, \"r\") as f:\n",
    "                existing_comments = json.load(f).get(\"data\", [])\n",
    "                existing_comment_ids = {c[\"id\"] for c in existing_comments}\n",
    "        else:\n",
    "            existing_comments = []\n",
    "    \n",
    "        if len(existing_comments) >= target_count:\n",
    "            print(f\"Already have {len(existing_comments)} comments for {post_id}\")\n",
    "            return existing_comments[:target_count]\n",
    "    \n",
    "        collected_comments = existing_comments[:]\n",
    "\n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "        headers = {\"Authorization\": f\"Bearer {self.bearer}\"}\n",
    "\n",
    "        attempts = 0\n",
    "        while len(collected_comments) < target_count and attempts < 10:\n",
    "            attempts += 1\n",
    "            added_this_round = 0\n",
    "            \n",
    "            # Define Timeframe\n",
    "            start, end = random_comment_window(tweet_created_at, window_days=2)\n",
    "            print(f\"Fetching comments for {post_id} between {start} and {end}\")\n",
    "            \n",
    "            params = {\"query\": f\"conversation_id:{post_id}\",\n",
    "                      \"start_time\": start,\n",
    "                      \"end_time\": end,\n",
    "                      \"max_results\": 10,\n",
    "                     \"tweet.fields\": \"id,text,created_at\"}\n",
    "    \n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(\"SUCCESS\")\n",
    "                data = response.json().get(\"data\", [])\n",
    "\n",
    "                for tweet in data:\n",
    "                    cid = tweet['id']\n",
    "                    if cid not in existing_comment_ids:\n",
    "                        collected_comments.append(tweet)\n",
    "                        existing_comment_ids.add(cid)\n",
    "                        added_this_round += 1\n",
    "\n",
    "                    if len(collected_comments) >= target_count:\n",
    "                        break\n",
    "                if added_this_round == 0:\n",
    "                    print(\"No new comments found - stopping early\")\n",
    "                    break\n",
    "                \n",
    "            elif response.status_code == 429:\n",
    "                reset = response.headers.get(\"x-rate-limit-reset\")\n",
    "                wait = int(reset) - int(time.time()) if reset else 60\n",
    "                print(f\"→ RATE LIMIT HIT. Sleeping {wait} seconds…\")\n",
    "                time.sleep(wait)\n",
    "            else: #other Errors\n",
    "                print(\"→ ERROR:\", response.text)\n",
    "                response.raise_for_status()\n",
    "\n",
    "        save_json({\"data\": collected_comments[:target_count]},\n",
    "                  folder=post_folder,\n",
    "                  filename=\"comments.json\")\n",
    "\n",
    "        return collected_comments[:target_count]\n",
    "\n",
    "class ToxicityApp:\n",
    "    def __init__(self):\n",
    "        if self.load_key():\n",
    "            self.api = RealAPIClient(self.key, self.bearer)\n",
    "        else:\n",
    "            self.api = DummyAPIClient()\n",
    "\n",
    "    def load_key(self):\n",
    "        try:\n",
    "            with open(\"key.json\") as f:\n",
    "                data = json.load(f)\n",
    "                self.key = data[\"X_API_KEY\"]\n",
    "                self.bearer = data[\"bearer_token\"]\n",
    "            return True\n",
    "        except:\n",
    "            print(\"Could not load key.\")\n",
    "            return False\n",
    "\n",
    "    def collect_politician_comments(self, \n",
    "                                    handles: list[str], \n",
    "                                    randomize_time: bool = True\n",
    "                                   ):\n",
    "        \"\"\"\n",
    "        Handes a list of twitter handles, returns json of posts and comments\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for handle in handles:\n",
    "            print(f\"Collecting posts for {handle}\")\n",
    "            \n",
    "            posts_json, post_ids = self.api.fetch_posts(handle)\n",
    "            tweets = posts_json.get(\"data\", [])\n",
    "\n",
    "            if not post_ids:\n",
    "                print(f\"No posts found for {handle}.\")\n",
    "                results[handle] = {\"posts\": posts_json, \"comments\": {}}\n",
    "                continue\n",
    "                \n",
    "            comments_for_this_handle = {}\n",
    "\n",
    "            # Iterate posts\n",
    "            for tweet in tweets:\n",
    "                post_id = tweet[\"id\"]\n",
    "                created_at = tweet[\"created_at\"]\n",
    "\n",
    "                comment_data = self.api.fetch_comments(\n",
    "                    politician_handle=handle,\n",
    "                    post_id=post_id,\n",
    "                    tweet_created_at = created_at,\n",
    "                    target_count=10,\n",
    "                    randomize_time=randomize_time)\n",
    "                comments_for_this_handle[post_id] = comment_data\n",
    "        \n",
    "            # Store inside the results dictionary\n",
    "            results[handle] = {\n",
    "                \"posts\" : posts_json,\n",
    "                \"comments\": comments_for_this_handle\n",
    "            }\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d408168-63f4-4063-86c5-745f015e3e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting posts for SenTuberville\n",
      "Already have 10 posts for SenTuberville\n",
      "Already have 10 comments for 2017728095743258826\n",
      "Already have 10 comments for 2017694628565135366\n",
      "Already have 10 comments for 2017652854744297983\n",
      "Already have 10 comments for 2017386285246169465\n",
      "Already have 10 comments for 2017317137682206839\n",
      "Already have 10 comments for 2017316916092662166\n",
      "Already have 10 comments for 2017279766496190651\n",
      "Already have 10 comments for 2017232811292262430\n",
      "Already have 10 comments for 2016987700696428746\n",
      "Already have 10 comments for 2016956008489275700\n",
      "Collecting posts for SenKatieBritt\n",
      "Already have 10 posts for SenKatieBritt\n",
      "Already have 10 comments for 2017015700963930351\n",
      "Already have 10 comments for 2016923809404633530\n",
      "Already have 10 comments for 2016647154593329514\n",
      "Already have 10 comments for 2016596831652712774\n",
      "Already have 10 comments for 2016556770018119692\n",
      "Already have 10 comments for 2016289208462111120\n",
      "Already have 10 comments for 2017385652195659929\n",
      "Already have 10 comments for 2017267599441117469\n",
      "Already have 10 comments for 2017260766177460498\n",
      "Already have 10 comments for 2017231172867100725\n",
      "Collecting posts for lisamurkowski\n",
      "Fetching tweets for lisamurkowski between 2026-02-07T13:09:22Z and 2026-02-09T13:09:22Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for lisamurkowski between 2026-02-06T09:53:46Z and 2026-02-08T09:53:46Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for lisamurkowski between 2026-02-05T04:31:58Z and 2026-02-07T04:31:58Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for lisamurkowski between 2026-02-04T16:35:03Z and 2026-02-06T16:35:03Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for lisamurkowski between 2026-02-07T22:08:23Z and 2026-02-09T22:08:23Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/lisamurkowski\\lisamurkowski_posts.json\n",
      "Already have 10 comments for 2017401976233853031\n",
      "Already have 10 comments for 2019160684060147917\n",
      "Already have 10 comments for 2020666841027219849\n",
      "Collecting posts for SenDanSullivan\n",
      "Already have 10 posts for SenDanSullivan\n",
      "Already have 10 comments for 2018775866860359765\n",
      "Already have 10 comments for 2018489110604714306\n",
      "Already have 10 comments for 2018352666817228861\n",
      "Already have 10 comments for 2018077416544231789\n",
      "Already have 10 comments for 2017407877976056087\n",
      "Already have 10 comments for 2016991098141327471\n",
      "Fetching comments for 2019148194404610089 between 2026-02-04T20:36:58Z and 2026-02-06T20:36:58Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenDanSullivan/2019148194404610089\\comments.json\n",
      "Already have 10 comments for 2019169796726911357\n",
      "Already have 10 comments for 2019850836147617937\n",
      "Already have 10 comments for 2019558294030020674\n",
      "Collecting posts for SenRubenGallego\n",
      "Already have 10 posts for SenRubenGallego\n",
      "Already have 10 comments for 2018435577364783580\n",
      "Already have 10 comments for 2018434108867637523\n",
      "Already have 10 comments for 2017641816489697512\n",
      "Already have 10 comments for 2017413318026117338\n",
      "Already have 10 comments for 2017368734483018118\n",
      "Already have 10 comments for 2017342855048482987\n",
      "Already have 10 comments for 2017274867419107651\n",
      "Already have 10 comments for 2018821716240196082\n",
      "Already have 10 comments for 2018763554132783573\n",
      "Already have 10 comments for 2018748642107199757\n",
      "Collecting posts for SenMarkKelly\n",
      "Already have 10 posts for SenMarkKelly\n",
      "Already have 10 comments for 2018384059890602197\n",
      "Already have 10 comments for 2018014302989345240\n",
      "Already have 10 comments for 2019186959810433143\n",
      "Already have 10 comments for 2019174525653430579\n",
      "Already have 10 comments for 2019135374640001467\n",
      "Already have 10 comments for 2019121781886579112\n",
      "Already have 10 comments for 2019091415616344168\n",
      "Already have 10 comments for 2018830412265713765\n",
      "Already have 10 comments for 2018788515585393003\n",
      "Already have 10 comments for 2018763827454546368\n",
      "Collecting posts for JohnBoozman\n",
      "Already have 10 posts for JohnBoozman\n",
      "Already have 10 comments for 2018701002292023794\n",
      "Already have 10 comments for 2018684330302722514\n",
      "Already have 10 comments for 2018445022379851990\n",
      "Already have 10 comments for 2018349083560218665\n",
      "Already have 10 comments for 2018328894915457167\n",
      "Already have 10 comments for 2018122491688858026\n",
      "Already have 10 comments for 2017740788013105607\n",
      "Already have 10 comments for 2017717714912219646\n",
      "Already have 10 comments for 2018749849781338573\n",
      "Fetching comments for 2018820179296387241 between 2026-02-03T22:53:33Z and 2026-02-05T22:53:33Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/JohnBoozman/2018820179296387241\\comments.json\n",
      "Collecting posts for SenTomCotton\n",
      "Already have 10 posts for SenTomCotton\n",
      "Already have 10 comments for 2018124809524453800\n",
      "Already have 10 comments for 2017719795806798185\n",
      "Already have 10 comments for 2017668826628808993\n",
      "Already have 10 comments for 2017284474552176829\n",
      "Already have 10 comments for 2017269282954989836\n",
      "Already have 10 comments for 2017258622686757299\n",
      "Already have 10 comments for 2019102413458927869\n",
      "Already have 10 comments for 2019096404287762784\n",
      "Already have 10 comments for 2019091487263256800\n",
      "Already have 10 comments for 2019055912992788524\n",
      "Collecting posts for AlexPadilla4CA\n",
      "Fetching tweets for AlexPadilla4CA between 2026-02-04T18:07:08Z and 2026-02-06T18:07:08Z\n",
      "SUCCESS\n",
      "Fetching tweets for AlexPadilla4CA between 2026-02-05T08:35:39Z and 2026-02-07T08:35:39Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AlexPadilla4CA between 2026-02-05T02:34:18Z and 2026-02-07T02:34:18Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AlexPadilla4CA between 2026-02-06T07:51:14Z and 2026-02-08T07:51:14Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AlexPadilla4CA between 2026-02-05T04:28:49Z and 2026-02-07T04:28:49Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/AlexPadilla4CA\\AlexPadilla4CA_posts.json\n",
      "Fetching comments for 2019144144707547598 between 2026-02-04T20:20:52Z and 2026-02-06T20:20:52Z\n",
      "SUCCESS\n",
      "Saved → data/posts/AlexPadilla4CA/2019144144707547598\\comments.json\n",
      "Collecting posts for AdamSchiff\n",
      "Fetching tweets for AdamSchiff between 2026-02-06T08:10:24Z and 2026-02-08T08:10:24Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AdamSchiff between 2026-02-04T05:32:18Z and 2026-02-06T05:32:18Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AdamSchiff between 2026-02-05T02:39:54Z and 2026-02-07T02:39:54Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AdamSchiff between 2026-02-06T13:53:12Z and 2026-02-08T13:53:12Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for AdamSchiff between 2026-02-07T00:28:53Z and 2026-02-09T00:28:53Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/AdamSchiff\\AdamSchiff_posts.json\n",
      "Already have 10 comments for 2019848459243909489\n",
      "Collecting posts for MichaelBennet\n",
      "Fetching tweets for MichaelBennet between 2026-02-05T01:18:01Z and 2026-02-07T01:18:01Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for MichaelBennet between 2026-02-05T15:16:09Z and 2026-02-07T15:16:09Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for MichaelBennet between 2026-02-04T10:39:03Z and 2026-02-06T10:39:03Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for MichaelBennet between 2026-02-05T22:59:13Z and 2026-02-07T22:59:13Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for MichaelBennet between 2026-02-07T03:00:15Z and 2026-02-09T03:00:15Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/MichaelBennet\\MichaelBennet_posts.json\n",
      "Already have 10 comments for 2018412264127123727\n",
      "Already have 10 comments for 2017383787156660270\n",
      "Already have 10 comments for 2017314146774085951\n",
      "Already have 10 comments for 2019453933026996522\n",
      "Already have 10 comments for 2019229162331075000\n",
      "Already have 10 comments for 2019850039607325017\n",
      "Collecting posts for SenatorHick\n",
      "Fetching tweets for SenatorHick between 2026-02-07T13:48:21Z and 2026-02-09T13:48:21Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenatorHick between 2026-02-04T08:33:18Z and 2026-02-06T08:33:18Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick\\SenatorHick_posts.json\n",
      "Fetching comments for 2020643671582855342 between 2026-02-08T23:39:27Z and 2026-02-10T20:13:46Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2020643671582855342\\comments.json\n",
      "Fetching comments for 2020542609815413177 between 2026-02-08T16:57:52Z and 2026-02-10T16:57:52Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenatorHick/2020542609815413177\\comments.json\n",
      "Fetching comments for 2020542606321598663 between 2026-02-08T16:57:51Z and 2026-02-10T16:57:51Z\n",
      "SUCCESS\n",
      "Fetching comments for 2020542606321598663 between 2026-02-08T16:57:51Z and 2026-02-10T16:57:51Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenatorHick/2020542606321598663\\comments.json\n",
      "Fetching comments for 2020232983022825609 between 2026-02-07T20:27:31Z and 2026-02-09T20:27:31Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2020232983022825609\\comments.json\n",
      "Fetching comments for 2020176133245874301 between 2026-02-07T16:41:37Z and 2026-02-09T16:41:37Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2020176133245874301\\comments.json\n",
      "Fetching comments for 2019584644509790617 between 2026-02-06T01:31:15Z and 2026-02-08T01:31:15Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2019584644509790617\\comments.json\n",
      "Fetching comments for 2019537424976842833 between 2026-02-05T22:23:37Z and 2026-02-07T22:23:37Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2019537424976842833\\comments.json\n",
      "Fetching comments for 2019473298485309454 between 2026-02-05T18:08:49Z and 2026-02-07T18:08:49Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2019473298485309454\\comments.json\n",
      "Fetching comments for 2019429218913001906 between 2026-02-05T15:13:39Z and 2026-02-07T15:13:39Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2019429218913001906\\comments.json\n",
      "Fetching comments for 2019187094380507505 between 2026-02-04T23:11:32Z and 2026-02-06T23:11:32Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenatorHick/2019187094380507505\\comments.json\n",
      "Collecting posts for SenBlumenthal\n",
      "Fetching tweets for SenBlumenthal between 2026-02-07T14:52:20Z and 2026-02-09T14:52:20Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenBlumenthal between 2026-02-04T05:19:22Z and 2026-02-06T05:19:22Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal\\SenBlumenthal_posts.json\n",
      "Fetching comments for 2020278239260815768 between 2026-02-07T23:27:21Z and 2026-02-09T23:27:21Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2020278239260815768\\comments.json\n",
      "Fetching comments for 2020175346910511554 between 2026-02-07T16:38:30Z and 2026-02-09T16:38:30Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2020175346910511554\\comments.json\n",
      "Fetching comments for 2020156238567203280 between 2026-02-07T15:22:34Z and 2026-02-09T15:22:34Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2020156238567203280\\comments.json\n",
      "Fetching comments for 2019543790537916776 between 2026-02-05T22:48:55Z and 2026-02-07T22:48:55Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019543790537916776\\comments.json\n",
      "Fetching comments for 2019204947024441464 between 2026-02-05T00:22:29Z and 2026-02-07T00:22:29Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019204947024441464\\comments.json\n",
      "Fetching comments for 2019198654964478322 between 2026-02-04T23:57:28Z and 2026-02-06T23:57:28Z\n",
      "SUCCESS\n",
      "Fetching comments for 2019198654964478322 between 2026-02-04T23:57:28Z and 2026-02-06T23:57:28Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenBlumenthal/2019198654964478322\\comments.json\n",
      "Fetching comments for 2019156607444062548 between 2026-02-04T21:10:23Z and 2026-02-06T21:10:23Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019156607444062548\\comments.json\n",
      "Fetching comments for 2019129900821807214 between 2026-02-04T19:24:16Z and 2026-02-06T19:24:16Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019129900821807214\\comments.json\n",
      "Fetching comments for 2019111323922231503 between 2026-02-04T18:10:27Z and 2026-02-06T18:10:27Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019111323922231503\\comments.json\n",
      "Fetching comments for 2019093115341316436 between 2026-02-04T16:58:06Z and 2026-02-06T16:58:06Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenBlumenthal/2019093115341316436\\comments.json\n",
      "Collecting posts for ChrisMurphyCT\n",
      "Fetching tweets for ChrisMurphyCT between 2026-02-06T06:33:40Z and 2026-02-08T06:33:40Z\n",
      "SUCCESS\n",
      "Fetching tweets for ChrisMurphyCT between 2026-02-05T04:29:50Z and 2026-02-07T04:29:50Z\n",
      "SUCCESS\n",
      "Fetching tweets for ChrisMurphyCT between 2026-02-04T10:11:42Z and 2026-02-06T10:11:42Z\n",
      "SUCCESS\n",
      "Fetching tweets for ChrisMurphyCT between 2026-02-05T00:12:01Z and 2026-02-07T00:12:01Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for ChrisMurphyCT between 2026-02-04T07:58:59Z and 2026-02-06T07:58:59Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/ChrisMurphyCT\\ChrisMurphyCT_posts.json\n",
      "Fetching comments for 2019873414362853490 between 2026-02-06T20:38:44Z and 2026-02-08T20:38:44Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019873414362853490\\comments.json\n",
      "Fetching comments for 2019872541159092575 between 2026-02-06T20:35:15Z and 2026-02-08T20:35:15Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019872541159092575\\comments.json\n",
      "Fetching comments for 2019853469390368845 between 2026-02-06T19:19:28Z and 2026-02-08T19:19:28Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019853469390368845\\comments.json\n",
      "Fetching comments for 2019841118851191211 between 2026-02-06T18:30:24Z and 2026-02-08T18:30:24Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019841118851191211\\comments.json\n",
      "Fetching comments for 2019774400686383549 between 2026-02-06T14:05:17Z and 2026-02-08T14:05:17Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019774400686383549\\comments.json\n",
      "Fetching comments for 2019483725117939942 between 2026-02-05T18:50:14Z and 2026-02-07T18:50:14Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019483725117939942\\comments.json\n",
      "Fetching comments for 2019439638088159514 between 2026-02-05T15:55:03Z and 2026-02-07T15:55:03Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019439638088159514\\comments.json\n",
      "Fetching comments for 2019438681761677570 between 2026-02-05T15:51:15Z and 2026-02-07T15:51:15Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019438681761677570\\comments.json\n",
      "Fetching comments for 2019071563115417927 between 2026-02-04T15:32:27Z and 2026-02-06T15:32:27Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisMurphyCT/2019071563115417927\\comments.json\n",
      "Collecting posts for SenLBR\n",
      "Fetching tweets for SenLBR between 2026-02-04T17:27:36Z and 2026-02-06T17:27:36Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenLBR between 2026-02-04T16:32:28Z and 2026-02-06T16:32:28Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for SenLBR between 2026-02-06T16:43:08Z and 2026-02-08T16:43:08Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenLBR between 2026-02-05T15:39:43Z and 2026-02-07T15:39:43Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for SenLBR between 2026-02-06T07:39:55Z and 2026-02-08T07:39:55Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Saved → data/posts/SenLBR\\SenLBR_posts.json\n",
      "Fetching comments for 2019797770945560760 between 2026-02-06T15:38:09Z and 2026-02-08T15:38:09Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenLBR/2019797770945560760\\comments.json\n",
      "Fetching comments for 2019534886328234327 between 2026-02-05T22:13:32Z and 2026-02-07T22:13:32Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenLBR/2019534886328234327\\comments.json\n",
      "Fetching comments for 2019445220547379239 between 2026-02-05T16:17:14Z and 2026-02-07T16:17:14Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenLBR/2019445220547379239\\comments.json\n",
      "Fetching comments for 2020199902064869562 between 2026-02-07T18:16:04Z and 2026-02-09T18:16:04Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenLBR/2020199902064869562\\comments.json\n",
      "Fetching comments for 2019836991484096644 between 2026-02-06T18:14:00Z and 2026-02-08T18:14:00Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenLBR/2019836991484096644\\comments.json\n",
      "Collecting posts for ChrisCoons\n",
      "Fetching tweets for ChrisCoons between 2026-02-06T20:04:01Z and 2026-02-08T20:04:01Z\n",
      "SUCCESS\n",
      "Fetching tweets for ChrisCoons between 2026-02-05T19:30:26Z and 2026-02-07T19:30:26Z\n",
      "SUCCESS\n",
      "Fetching tweets for ChrisCoons between 2026-02-06T11:51:47Z and 2026-02-08T11:51:47Z\n",
      "SUCCESS\n",
      "No new posts found - stopping early\n",
      "Fetching tweets for ChrisCoons between 2026-02-04T11:01:50Z and 2026-02-06T11:01:50Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons\\ChrisCoons_posts.json\n",
      "Fetching comments for 2019891344945344704 between 2026-02-06T21:49:59Z and 2026-02-08T21:49:59Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019891344945344704\\comments.json\n",
      "Fetching comments for 2019870670923104705 between 2026-02-06T20:27:49Z and 2026-02-08T20:27:49Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019870670923104705\\comments.json\n",
      "Fetching comments for 2019782829228302755 between 2026-02-06T14:38:46Z and 2026-02-08T14:38:46Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/ChrisCoons/2019782829228302755\\comments.json\n",
      "Fetching comments for 2019782827714199947 between 2026-02-06T14:38:46Z and 2026-02-08T14:38:46Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019782827714199947\\comments.json\n",
      "Fetching comments for 2019539028484219258 between 2026-02-05T22:30:00Z and 2026-02-07T22:30:00Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019539028484219258\\comments.json\n",
      "Fetching comments for 2019519097797750860 between 2026-02-05T21:10:48Z and 2026-02-07T21:10:48Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019519097797750860\\comments.json\n",
      "Fetching comments for 2019508656468029620 between 2026-02-05T20:29:19Z and 2026-02-07T20:29:19Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019508656468029620\\comments.json\n",
      "Fetching comments for 2019491188294795452 between 2026-02-05T19:19:54Z and 2026-02-07T19:19:54Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019491188294795452\\comments.json\n",
      "Fetching comments for 2019458716613894257 between 2026-02-05T17:10:52Z and 2026-02-07T17:10:52Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019458716613894257\\comments.json\n",
      "Fetching comments for 2019173439467069832 between 2026-02-04T22:17:17Z and 2026-02-06T22:17:17Z\n",
      "SUCCESS\n",
      "Saved → data/posts/ChrisCoons/2019173439467069832\\comments.json\n",
      "Collecting posts for SenAshleyMoody\n",
      "Fetching tweets for SenAshleyMoody between 2026-02-07T19:03:24Z and 2026-02-09T19:03:24Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenAshleyMoody between 2026-02-04T13:29:29Z and 2026-02-06T13:29:29Z\n",
      "SUCCESS\n",
      "Fetching tweets for SenAshleyMoody between 2026-02-06T17:47:42Z and 2026-02-08T17:47:42Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody\\SenAshleyMoody_posts.json\n",
      "Fetching comments for 2020898507683455089 between 2026-02-09T16:32:05Z and 2026-02-10T20:14:22Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2020898507683455089\\comments.json\n",
      "Fetching comments for 2019584166472323314 between 2026-02-06T01:29:22Z and 2026-02-08T01:29:22Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019584166472323314\\comments.json\n",
      "Fetching comments for 2019523104876450122 between 2026-02-05T21:26:43Z and 2026-02-07T21:26:43Z\n",
      "SUCCESS\n",
      "Fetching comments for 2019523104876450122 between 2026-02-05T21:26:43Z and 2026-02-07T21:26:43Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenAshleyMoody/2019523104876450122\\comments.json\n",
      "Fetching comments for 2019502181150322886 between 2026-02-05T20:03:35Z and 2026-02-07T20:03:35Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019502181150322886\\comments.json\n",
      "Fetching comments for 2019486209479704910 between 2026-02-05T19:00:07Z and 2026-02-07T19:00:07Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019486209479704910\\comments.json\n",
      "Fetching comments for 2019192271565123647 between 2026-02-04T23:32:06Z and 2026-02-06T23:32:06Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019192271565123647\\comments.json\n",
      "Fetching comments for 2019065216684654722 between 2026-02-04T15:07:14Z and 2026-02-06T15:07:14Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019065216684654722\\comments.json\n",
      "Fetching comments for 2019964091188802030 between 2026-02-07T02:39:03Z and 2026-02-09T02:39:03Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019964091188802030\\comments.json\n",
      "Fetching comments for 2019924166158479545 between 2026-02-07T00:00:24Z and 2026-02-09T00:00:24Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenAshleyMoody/2019924166158479545\\comments.json\n",
      "Fetching comments for 2019882099109761395 between 2026-02-06T21:13:14Z and 2026-02-08T21:13:14Z\n",
      "SUCCESS\n",
      "Fetching comments for 2019882099109761395 between 2026-02-06T21:13:14Z and 2026-02-08T21:13:14Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenAshleyMoody/2019882099109761395\\comments.json\n",
      "Collecting posts for SenRickScott\n",
      "Fetching tweets for SenRickScott between 2026-02-04T09:45:49Z and 2026-02-06T09:45:49Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott\\SenRickScott_posts.json\n",
      "Fetching comments for 2019571796324786208 between 2026-02-06T00:40:12Z and 2026-02-08T00:40:12Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019571796324786208\\comments.json\n",
      "Fetching comments for 2019565001456120122 between 2026-02-06T00:13:12Z and 2026-02-08T00:13:12Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019565001456120122\\comments.json\n",
      "Fetching comments for 2019554943410270562 between 2026-02-05T23:33:14Z and 2026-02-07T23:33:14Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019554943410270562\\comments.json\n",
      "Fetching comments for 2019544294340575537 between 2026-02-05T22:50:55Z and 2026-02-07T22:50:55Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019544294340575537\\comments.json\n",
      "Fetching comments for 2019520548188086612 between 2026-02-05T21:16:34Z and 2026-02-07T21:16:34Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019520548188086612\\comments.json\n",
      "Fetching comments for 2019496378112569611 between 2026-02-05T19:40:31Z and 2026-02-07T19:40:31Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019496378112569611\\comments.json\n",
      "Fetching comments for 2019474676523663453 between 2026-02-05T18:14:17Z and 2026-02-07T18:14:17Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019474676523663453\\comments.json\n",
      "Fetching comments for 2019421748429754397 between 2026-02-05T14:43:58Z and 2026-02-07T14:43:58Z\n",
      "SUCCESS\n",
      "No new comments found - stopping early\n",
      "Saved → data/posts/SenRickScott/2019421748429754397\\comments.json\n",
      "Fetching comments for 2019421745925763293 between 2026-02-05T14:43:57Z and 2026-02-07T14:43:57Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019421745925763293\\comments.json\n",
      "Fetching comments for 2019244593771102278 between 2026-02-05T03:00:01Z and 2026-02-07T03:00:01Z\n",
      "SUCCESS\n",
      "Saved → data/posts/SenRickScott/2019244593771102278\\comments.json\n"
     ]
    }
   ],
   "source": [
    "app = ToxicityApp()\n",
    "\n",
    "results = app.collect_politician_comments(\n",
    "    [\"SenTuberville\",\n",
    "     \"SenKatieBritt\",\n",
    "     \"lisamurkowski\",\n",
    "     \"SenDanSullivan\",\n",
    "     \"SenRubenGallego\",\n",
    "     \"SenMarkKelly\",\n",
    "     \"JohnBoozman\",\n",
    "     \"SenTomCotton\",\n",
    "     \"AlexPadilla4CA\",\n",
    "     \"AdamSchiff\",\n",
    "     \"MichaelBennet\",\n",
    "     \"SenatorHick\", \n",
    "     \"SenBlumenthal\", \n",
    "     \"ChrisMurphyCT\", \n",
    "     \"SenLBR\", \n",
    "     \"ChrisCoons\", \n",
    "     \"SenAshleyMoody\", \n",
    "     \"SenRickScott\",\n",
    "     \"SenOssoff\", \n",
    "     \"SenatorWarnock\", \n",
    "     \"SenBrianSchatz\",\n",
    "     \"maziehirono\", \n",
    "     \"MikeCrapo\", \n",
    "     \"SenatorRisch\", \n",
    "     \"SenatorDurbin\"\n",
    "    ],\n",
    "    randomize_time=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd75d9-c320-4ee6-9640-a758eb7fc632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SenatorHick',\n",
       " 'SenBlumenthal',\n",
       " 'ChrisMurphyCT',\n",
       " 'SenLBR',\n",
       " 'ChrisCoons',\n",
       " 'SenAshleyMoody',\n",
       " 'SenRickScott',\n",
       " 'SenOssoff',\n",
       " 'SenatorWarnock',\n",
       " 'SenBrianSchatz',\n",
       " 'maziehirono',\n",
       " 'MikeCrapo',\n",
       " 'SenatorRisch',\n",
       " 'SenatorDurbin',\n",
       " 'SenDuckworth',\n",
       " 'SenToddYoung',\n",
       " 'SenatorBanks',\n",
       " 'ChuckGrassley',\n",
       " 'SenJoniErnst',\n",
       " 'JerryMoran',\n",
       " 'RogerMarshallMD',\n",
       " 'McConnellPress',\n",
       " 'RandPaul',\n",
       " 'BillCassidy',\n",
       " 'SenJohnKennedy',\n",
       " 'SenatorCollins',\n",
       " 'SenAngusKing',\n",
       " 'Sen_Alsobrooks',\n",
       " 'ChrisVanHollen',\n",
       " 'SenWarren',\n",
       " 'SenMarkey',\n",
       " 'SenatorSlotkin',\n",
       " 'SenGaryPeters',\n",
       " 'amyklobuchar',\n",
       " 'SenTinaSmith',\n",
       " 'SenatorWicker',\n",
       " 'SenHydeSmith',\n",
       " 'SenHawleyPress',\n",
       " 'SenEricSchmitt',\n",
       " 'TimSheehyMT',\n",
       " 'SteveDaines',\n",
       " 'SenatorFischer',\n",
       " 'SenatorRicketts',\n",
       " 'SenCortezMasto',\n",
       " 'SenJackyRosen',\n",
       " 'SenatorShaheen',\n",
       " 'SenatorHassan',\n",
       " 'SenBooker',\n",
       " 'AndyKimNJ',\n",
       " 'MartinHeinrich',\n",
       " 'SenatorLujan',\n",
       " 'SenSchumer',\n",
       " 'gillibrandny',\n",
       " 'SenThomTillis',\n",
       " 'SenTedBuddNC',\n",
       " 'SenJohnHoeven',\n",
       " 'SenKevinCramer',\n",
       " 'berniemoreno',\n",
       " 'SenJonHusted',\n",
       " 'SenatorLankford',\n",
       " 'SenMullin',\n",
       " 'RonWyden',\n",
       " 'SenJeffMerkley',\n",
       " 'DaveMcCormickPA',\n",
       " 'SenFettermanPA',\n",
       " 'SenJackReed',\n",
       " 'SenWhitehouse',\n",
       " 'LindseyGrahamSC',\n",
       " 'SenatorTimScott',\n",
       " 'johnthune',\n",
       " 'SenatorRounds',\n",
       " 'MarshaBlackburn',\n",
       " 'SenatorHagerty',\n",
       " 'JohnCornyn',\n",
       " 'SenTedCruz',\n",
       " 'SenJohnCurtis',\n",
       " 'SenMikeLee',\n",
       " 'SenSanders',\n",
       " 'WelchForVT',\n",
       " 'MarkWarner',\n",
       " 'timkaine',\n",
       " 'PattyMurray',\n",
       " 'SenatorCantwell',\n",
       " 'JimJustice_WV',\n",
       " 'SenCapito',\n",
       " 'SenRonJohnson',\n",
       " 'SenatorBaldwin',\n",
       " 'SenJohnBarrasso',\n",
       " 'SenLummis']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"SenOssoff\", \"SenatorWarnock\", \"SenBrianSchatz\",\"maziehirono\", \"MikeCrapo\", \"SenatorRisch\", \"SenatorDurbin\",\n",
    "\"SenDuckworth\", \"SenToddYoung\", \"SenatorBanks\", \"ChuckGrassley\", \"SenJoniErnst\", \"JerryMoran\" , \n",
    "\"RogerMarshallMD\", \"McConnellPress\", \"RandPaul\", \"BillCassidy\", \"SenJohnKennedy\", \"SenatorCollins\",\n",
    "\"SenAngusKing\", \"Sen_Alsobrooks\", \"ChrisVanHollen\", \"SenWarren\", \"SenMarkey\",\"SenatorSlotkin\",\n",
    "\"SenGaryPeters\", \"amyklobuchar\", \"SenTinaSmith\",\"SenatorWicker\",\"SenHydeSmith\", \"SenHawleyPress\", \n",
    "\"SenEricSchmitt\", \"TimSheehyMT\", \"SteveDaines\", \"SenatorFischer\", \"SenatorRicketts\" ,\"SenCortezMasto\",\n",
    "\"SenJackyRosen\", \"SenatorShaheen\", \"SenatorHassan\", \"SenBooker\", \"AndyKimNJ\", \"MartinHeinrich\",\n",
    "\"SenatorLujan\", \"SenSchumer\", \"gillibrandny\" , \"SenThomTillis\", \"SenTedBuddNC\" , \"SenJohnHoeven\",\n",
    "\"SenKevinCramer\", \"berniemoreno\", \"SenJonHusted\", \"SenatorLankford\", \"SenMullin\" , \"RonWyden\", \n",
    "\"SenJeffMerkley\", \"DaveMcCormickPA\", \"SenFettermanPA\", \"SenJackReed\", \"SenWhitehouse\", \n",
    "\"LindseyGrahamSC\", \"SenatorTimScott\", \"johnthune\" ,\"SenatorRounds\", \"MarshaBlackburn\",\n",
    "\"SenatorHagerty\", \"JohnCornyn\", \"SenTedCruz\", \"SenJohnCurtis\", \"SenMikeLee\", \"SenSanders\", \"WelchForVT\",\n",
    "\"MarkWarner\", \"timkaine\", \"PattyMurray\", \"SenatorCantwell\", \"JimJustice_WV\", \"SenCapito\", \"SenRonJohnson\",\n",
    "\"SenatorBaldwin\", \"SenJohnBarrasso\", \"SenLummis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cc0e0-f1c1-45b3-a5f6-886fec9c897e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
